---
title: "IMM reliability"
author: "Attila Szuts"
date: '2020 Ã¡prilis 9 '
output:
  html_document:
    toc: true
    theme: united
    number_sections: true
editor_options: 
  chunk_output_type: console
---
# Data input and opening libraries

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(readr)
library(tidyverse)
library(readxl)
library(lubridate)
library(ggplot2)
library(stringr)
library(vroom)
library(janitor)
library(widyr)
# library(data.table)
library(ggpubr)
library(vroom)
library(lubridate)
```

# Explicit

## Importing data

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
explicit_raw <-
  bind_rows(
    read_csv("data/Round 1/data.csv") %>% mutate(measurement = 1),
    read_csv("data/Round 2/data.csv") %>% mutate(measurement = 2)
  ) 
```

## Reversing items, creating groups, creating means of explicit measures

```{r}
explicit <- 
  explicit_raw %>% 
  tidyr::extract(col = participant, 
          into = c(NA, "id", NA), 
          regex = "^(.*s.)(.*)(.txt)$") %>% 
  clean_names() %>% 
  drop_na(time_end) %>% 
  mutate(neptun_1 = str_to_lower(neptun_1)) %>% 
  mutate_at(c("time_start", "time_end"), ymd_hm) %>% 
  mutate_at(c("time_start", "time_end"), as_date) %>% 
  group_by(measurement) %>% 
  distinct(neptun_1, .keep_all = TRUE) %>% 
  ungroup() %>% 
#creating 2-week and 4-week group, filtering participants that were only in one part  
  group_by(neptun_1) %>% 
  arrange(neptun_1, time_end) %>% 
  mutate(time_end_lag = time_end - dplyr::lag(time_end),
         time_end_lead = dplyr::lead(time_end)- time_end,
         time_end_lag = replace_na(time_end_lag, 0),
         time_end_lead = replace_na(time_end_lead, 0),
         time_end_diff = time_end_lag + time_end_lead) %>% 
  filter(time_end_diff > 0) %>% 
  mutate(group = ifelse(time_end_diff > 20, 1, 0)) %>% 
  select(-c(time_end_lag, time_end_lead, time_end)) %>% 
  ungroup() %>% 
#reversing items
  mutate_at(vars(iq1_1, iq2_1, fms3_1, fms4_1, cr_ms3_1, cr_ms4_1, ch_ms3_1, ch_ms4_1), 
            ~recode(., `1` = 6,
                    `2` = 5,
                    `3` = 4,
                    `4` = 3,
                    `5` = 2,
                    `6` = 1,
            )) %>% 
  mutate_at(vars(failurescenario_1, criticismscenario_1), 
            ~recode(., `1` = 5,
                    `2` = 4,
                    `4` = 2,
                    `5` = 1,
            )) %>% 
#creating means of explicit measures
  mutate(iqms_avg = rowMeans(x = select(.data = ., starts_with(match = "iq")))) %>% 
  mutate(crms_avg = rowMeans(x = select(.data = ., starts_with(match = "cr_ms")))) %>% 
  mutate(chms_avg = rowMeans(x = select(.data = ., starts_with(match = "ch_ms")))) %>% 
  mutate(fms_avg = rowMeans(x = select(.data = ., starts_with(match = "fms")))) %>% 
  mutate(fsc_avg = rowMeans(x = select(.data = ., starts_with(match = "failure")))) %>% 
  mutate(crsc_avg = rowMeans(x = select(.data = ., starts_with(match = "criticism")))) %>% 
  dplyr::select(neptun_1, id, gender_1, age_1, iqms_avg, crms_avg, chms_avg, fms_avg, fsc_avg, crsc_avg, challengescenario_1, measurement, group, time_end_diff)
```

Neptun codes that were removed from second round
```{r}
excluded <- setdiff(explicit_raw %>% filter(measurement == 2) %>% mutate(neptun_1 = tolower(`Neptun:1`)) %$% neptun_1,
                    explicit %>% filter(measurement == 2) %$% neptun_1)
#participant ids that were removed from explicit because they didn't complete second round
excluded_id <- explicit_raw %>% filter(`Neptun:1` %in% excluded) %$% participant
```

Counting number of participants in groups
The 2 week group is coded as group 0, the 4 week group is coded as group 1.
```{r}
explicit %>% 
  count(group)
```

Plotting frequency of number of days between data collections
```{r}
ggplot(explicit, aes(time_end_diff)) +
  geom_bar() + 
  xlab('Days between measures') + 
  ylab('Number of particpants') + 
  theme_classic()
```

# Implicit

## Importing data
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
#defining path
files1 <- list.files(path = "D:/Documents/Egyebek/Thesis/data/Round 1", pattern = "immtest.*.txt$", full.names = TRUE)
files2 <- list.files(path = "D:/Documents/Egyebek/Thesis/data/Round 2", pattern = "immtest.*.txt$", full.names = TRUE)

#importing data files
gnat_raw <- 
  bind_rows(
  vroom::vroom(file = files1, 
        id = "id", 
        col_names = c("block", "block_id", "word", "max_rt", "trial_type", "word_category", "rt", "error", "target")) %>% mutate(measurement = 1),
  vroom::vroom(file = files2, 
        id = "id", 
        col_names = c("block", "block_id", "word", "max_rt", "trial_type", "word_category", "rt", "error", "target")) %>% mutate(measurement = 2)) %>% 
  tidyr::extract(col = id, 
          into = c(NA, "id", NA), 
          regex = "^(.*data.)(.*)(.txt)$")
```
## Filtering observations based on error rate 

Criteria: 

* Block error rate below 60%
* Overall error rate below 80%
* Erroneous association
* Response latency under 300 ms
* Response latency above 1399 ms

Determining average RT and SD for filter
```{r}
#important targets
important_targets <- c("chall_pos", "chall_neg", "crit_pos", "crit_neg")

#deleting rows with too quick and too slow response windows (too quick is 300 and too slow is 3 SD above average rt)
gnat_filter1 <- 
  gnat_raw %>% 
  filter(target %in% important_targets,
         trial_type == 'go_trial',
         measurement == 1) %>% 
  # checking for block error rate per participant
  group_by(id, target) %>% 
  mutate(correct_block = 1 - mean(error)) %>% 
  ungroup() %>% 
  # checking for overall error rate per participant
  group_by(id) %>% 
  mutate(correct_all = 1 - mean(error)) %>% 
  ungroup() %>% 
  filter(correct_block > 0.6 & correct_all > 0.8 & error == 0)
gnat_filter2 <- 
  gnat_raw %>% 
  filter(target %in% important_targets,
         trial_type == 'go_trial',
         measurement == 2) %>% 
  # checking for block error rate per participant
  group_by(id, target) %>% 
  mutate(correct_block = 1 - mean(error)) %>% 
  ungroup() %>% 
  # checking for overall error rate per participant
  group_by(id) %>% 
  mutate(correct_all = 1 - mean(error)) %>% 
  ungroup() %>% 
  filter(correct_block > 0.6 & correct_all > 0.8 & error == 0)
```

filtering observations and creating d-scores
```{r}
implicit <- 
  gnat_raw %>% 
  #filter only important trials and only go_trials 
  filter(target %in%important_targets,
         trial_type == 'go_trial') %>% 
  #filtering out participants that didnt complete the second round
  filter(!id %in% excluded_id) %>%
  #checking for block error rate per participant
  group_by(id, target) %>% 
  mutate(correct_block = 1 - mean(error)) %>% 
  ungroup() %>% 
  # checking for overall error rate per participant
  group_by(id) %>% 
  mutate(correct_all = 1 - mean(error)) %>% 
  ungroup() %>% 
  # filter overall and block error rates, filter too quick and too slow responses
  filter(correct_block > 0.6 & correct_all > 0.8 & error == 0,
         rt > 300 & rt < 1399) %>%
  #calculating d-scores
  group_by(measurement, id) %>% 
  mutate(pers_sd = sd(rt)) %>% 
  ungroup() %>% 
  group_by(measurement, id, target, pers_sd) %>% 
  summarise(pers_block_avg = mean(rt)) %>% 
  mutate(d = pers_block_avg/pers_sd) %>% 
  ungroup() %>% 
  select(-pers_block_avg, -pers_sd) %>%
  spread(target, d) %>% 
  mutate(challenge_d = chall_neg - chall_pos,
         crit_d = crit_neg - crit_pos)
```

# Unite implicit with explicit

Excluded participants that had too high error rate
```{r}
final <- left_join(explicit, implicit, by = c("id", "measurement")) %>% 
  filter(neptun_1 != "q69vn2",
         neptun_1 != "bm0vx1")
```


# Analysis

## Assumption checks

* implicit - implicit 
* split - half
* explicit - explicit
* words RT 
* implicit - explicit at the separate times

D-score normality test
```{r}
# normal
final %>% 
  filter(measurement == 1) %$%
  challenge_d %>% 
  shapiro.test()
final %>% 
  filter(measurement == 2) %$%
  challenge_d %>% 
  shapiro.test()

# not normal
final %>% 
  filter(measurement == 1) %$%
  crit_d %>% 
  shapiro.test()
final %>% 
  filter(measurement == 2) %$%
  crit_d %>% 
  shapiro.test()
```


## Hypothesis testing

```{r}
final1 <- final %>% 
  filter(measurement == 1) %>% 
  arrange(neptun_1)
final2 <- final %>% 
  filter(measurement == 2) %>% 
  arrange(neptun_1) 

cor.test(final1$challenge_d, final2$challenge_d, method = "pearson")
cor.test(final1$crit_d, final2$crit_d, method = "pearson")
```


## Plots and figures