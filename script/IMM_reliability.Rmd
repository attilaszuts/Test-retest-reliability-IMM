---
title: "IMM reliability"
author: "Attila Szuts"
date: '2020 Ã¡prilis 9 '
output:
  html_document:
    toc: true
    theme: united
    number_sections: true
editor_options: 
  chunk_output_type: console
---
```{r include=FALSE}
knitr::opts_knit$set(root.dir = "D:/Documents/Egyebek/Thesis")
```

# Data input and opening libraries

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(readr)
library(tidyverse)
library(readxl)
library(lubridate)
library(ggplot2)
library(stringr)
library(vroom)
library(janitor)
library(widyr)
# library(data.table)
library(ggpubr)
library(vroom)
library(lubridate)
```

# Creating groups

Reading in data files
```{r message=FALSE, warning=FALSE, paged.print=FALSE}

explicit_raw <-
  bind_rows(
    read_csv("data/Round 1/data.csv") %>% mutate(measurement = 1),
    read_csv("data/Round 2/data.csv") %>% mutate(measurement = 2)
  ) 

explicit <- 
  explicit_raw %>% 
  tidyr::extract(col = participant, 
          into = c(NA, "id", NA), 
          regex = "^(.*s.)(.*)(.txt)$") %>% 
  clean_names() %>% 
  drop_na(time_end) %>% 
  mutate(neptun_1 = str_to_lower(neptun_1)) %>% 
  mutate_at(c("time_start", "time_end"), ymd_hm) %>% 
  mutate_at(c("time_start", "time_end"), as_date) %>% 
  group_by(measurement) %>% 
  distinct(neptun_1, .keep_all = TRUE) %>% 
  ungroup() %>% 
#creating 2-week and 4-week group    

#reversing items
  mutate_at(vars(iq1_1, iq2_1, fms3_1, fms4_1, cr_ms3_1, cr_ms4_1, ch_ms3_1, ch_ms4_1), 
            ~recode(., `1` = 6,
                    `2` = 5,
                    `3` = 4,
                    `4` = 3,
                    `5` = 2,
                    `6` = 1,
            )) %>% 
  mutate_at(vars(failurescenario_1, criticismscenario_1), 
            ~recode(., `1` = 5,
                    `2` = 4,
                    `4` = 2,
                    `5` = 1,
            )) %>% 
#creating means of explicit measures
  mutate(iqms_avg = rowMeans(x = select(.data = ., starts_with(match = "iq")))) %>% 
  mutate(crms_avg = rowMeans(x = select(.data = ., starts_with(match = "cr_ms")))) %>% 
  mutate(chms_avg = rowMeans(x = select(.data = ., starts_with(match = "ch_ms")))) %>% 
  mutate(fms_avg = rowMeans(x = select(.data = ., starts_with(match = "fms")))) %>% 
  mutate(fsc_avg = rowMeans(x = select(.data = ., starts_with(match = "failure")))) %>% 
  mutate(crsc_avg = rowMeans(x = select(.data = ., starts_with(match = "criticism")))) %>% 
  select(neptun_1, id, gender_1, age_1, iqms_avg, crms_avg, chms_avg, fms_avg, fsc_avg, crsc_avg, challengescenario_1, measurement)

```

## Creating groups (2 week and 4 week)

### Adding 'days between data collections' column and filtering missing values
```{r}
joined <- joined %>% 
  mutate(
    TIME_between_end = TIME_end_second - TIME_end_first
  ) 
#this should be empty
missing_joined_TIME_between <- joined %>% 
  dplyr::filter(is.na("TIME_end_between"))
joined <- joined %>% 
  drop_na(TIME_between_end)
```

### Counting number of participants in groups
The 2 week group is coded as group 0, the 4 week group is coded as group 1.
```{r}
joined$group <- ifelse(joined$TIME_between_end > 20, 1, 0)
# if there are more than 20 days between administration it is assigned 1, else 0
joined %>% 
  count(group)
joined <- joined %>% 
  rename(neptun = `Neptun:1`)
```

## Plotting frequency of number of days between data collections
```{r}
joined$TIME_between_end <- as.numeric(joined$TIME_between_end)
ggplot(joined, aes(TIME_between_end)) +
  geom_bar() + 
  xlab('Days between measures') + 
  ylab('Number of particpants') + 
  theme_classic()
```

# Round 1 data

## Implicit measure
### Data cleaning
Importing data
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
#defining path
files1 <- list.files(path = "D:/Documents/Egyebek/Thesis/data/Round 1", pattern = "immtest.*.txt$", full.names = TRUE)

#importing data files
gnat_raw1 <- 
  vroom::vroom(file = files1, 
        id = "id", 
        col_names = c("block", "block_id", "word", "max_rt", "trial_type", "word_category", "rt", "error", "target")) %>% 
  extract(col = id, 
          into = c(NA, "id", NA), 
          regex = "^(.*data.)(.*)(.txt)$")
```
Keeping only important blocks
```{r}
important_targets <- c("chall_pos", "chall_neg", "crit_pos", "crit_neg")

#filter only important trials and only go_trials for first round
gnat_important1 <- 
  gnat_raw1 %>% 
  filter(target %in%important_targets) %>% 
  filter(trial_type == 'go_trial')
```
Establishing block error rate per participant
```{r}
#checking for block error rate above 40% for first round
correct_block_rate1 <- 
  gnat_important1 %>% 
  group_by(id, target) %>% 
  summarise(correct_block = 1 - mean(error))
```
Establishing overall error rate per participant
```{r}
#no more removal needed for round 1
correct_all_rate1 <-
  gnat_important1 %>% 
  filter(target %in% important_targets) %>%
  group_by(id) %>% 
  summarise(correct_all = 1 - mean(error))
```
Filtering observations based on error rate 

Criteria: 

* Block error rate below 60%
* Overall error rate below 80%
* Erroneous association
* Response latency under 300 ms
* Response latency $3*SD$ above average RT

Determining average RT and SD for previous filter
```{r}
#deleting rows with too quick and too slow response windows for round1 (too quick is 300 and too slow is 3 SD above average rt)
rt_mean1 <- as.integer(gnat_important1 %>% 
                         left_join(correct_block_rate1, by = c("id", "target")) %>% 
                         left_join(correct_all_rate1, by = c("id")) %>% 
                         filter(correct_block > 0.6 & correct_all > 0.8 & error == 0) %>% 
                         summarise(pers_a = mean(rt)))

rt_sd1 <- as.integer(gnat_important1 %>% 
                       left_join(correct_block_rate1, by = c("id", "target")) %>% 
                       left_join(correct_all_rate1, by = c("id")) %>% 
                       filter(correct_block > 0.6 & correct_all > 0.8 & error == 0) %>% 
                       summarise(pers_sd = sd(rt)))

rt_filter1 <- (rt_sd1 * 3) + rt_mean1
```

Deleting rows based on exclusion criteria
```{r}
#must delete these observations due to high block error rate from round1
final_gnat1 <-
  gnat_important1 %>% 
  left_join(correct_block_rate1, by = c("id", "target")) %>% 
  left_join(correct_all_rate1, by = c("id")) %>% 
  filter(correct_block > 0.6 & correct_all > 0.8 & error == 0) %>% 
  filter(rt > 300 & rt < rt_filter1)
```
Rows that have been removed

Every row that has been removed from further analysis.
```{r}
final_diff1 <- 
  dplyr::setdiff(gnat_important1, final_gnat1[, -c(11,12)])
```

Participants that have been excluded due to high overall error rate.
```{r}
#participants from round 1 that had exceeded 80% error rate
participants_removed1 <- 
  gnat_important1 %>% 
  left_join(correct_all_rate1, by = c("id")) %>%
  filter(correct_all <= 0.8)
p_rem_id1 <- unique(participants_removed1$id)
```
number of participants removed from first round:
```{r}
length(p_rem_id1)
```
Calculating d-scores
```{r}
#d-scores for round 1
dscores1 <-
  final_gnat1 %>% 
  group_by(id) %>% 
  mutate(pers_sd = sd(rt)) %>% 
  group_by(id, target, pers_sd) %>% 
  summarise(pers_block_avg = mean(rt)) %>% 
  mutate(d = pers_block_avg/pers_sd) %>% 
  ungroup() %>% 
  select(-pers_block_avg, -pers_sd) %>%
  spread(target, d) %>% 
  mutate(challange_d = chall_neg - chall_pos,
         crit_d = crit_neg - crit_pos)
```